{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:21:16.249717Z",
     "start_time": "2024-01-06T03:21:16.234189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Namespace(ablation=0, bs=64, dataset='1', debug=0, decay=0.001, density=0.1, device='cpu', dimension=64, epochs=150, exper=4, experiment=0, loss_func='L1Loss', lr=0.001, lr_step=100, model='4', optim='AdamW', path='./datasets/', patience=20, program_test=0, record=0, rounds=5, saved=1, seed=0, valid=1, verbose=10, windows=5)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import get_args\n",
    "args = get_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = 'https://api.openai-proxy.org/v1'\n",
    "openai.api_key = 'sk-jrgIM6P2VqRkWIH1BcwfUCY1vulqfrsBaU0d7i7bFYFy502l'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:21:16.249962Z",
     "start_time": "2024-01-06T03:21:16.238023Z"
    }
   },
   "id": "d374cc09036978f4",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from modules.datasets.chatgpt import NAS_ChatGPT\n",
    "large_model = NAS_ChatGPT(args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:21:16.251102Z",
     "start_time": "2024-01-06T03:21:16.244461Z"
    }
   },
   "id": "2ad0a1fff12a871d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pre_str = \"You are now a search engines, and required to provide the inquired information of the given processer.\\n\"\n",
    "input_device = 'The processer is ' + 'core-i7-7820x' + '.\\n'\n",
    "output_format = \"The inquired information is : Maximum Turbo Boost Frequency, Number of Cores, Number of Threads, Level 3 Cache, Maximum Memory Bandwidth.\\n \\\n",
    "                And please output them in form of: Maximum_Turbo_Boost_Frequency::Number_of_Cores::Number_of_Threads::Level_3_Cache::Maximum_Memory_Bandwidth. \\n  \\\n",
    "                please output only the content in the form above, i.e., %.2lf GHz::%d cores::%d Threads::%.2lf MB::%.1lf GB/s\\n, \\\n",
    "                but no other thing else, no reasoning, no index.\\n\\n\"\n",
    "prompt = pre_str + input_device + output_format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:21:16.258451Z",
     "start_time": "2024-01-06T03:21:16.254051Z"
    }
   },
   "id": "657cbc9ed8567b07",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "温度（Temperature）：这个参数主要影响文本的随机性。较低的温度会导致模型的输出更加确定和重复，而较高的温度会使输出更加多样化和创造性。\n",
    "最大令牌数（Max Tokens）：这个参数设定了模型输出的最大长度。令牌通常可以理解为词或词的一部分。\n",
    "频率惩罚（Frequency Penalty）：这个参数使得模型在生成文本时减少重复单词或短语的倾向。\n",
    "存在惩罚（Presence Penalty）：这个参数鼓励模型生成之前没有出现过的新内容，从而提高创造性。\n",
    "截止策略（Stop Sequences）：这些是指示模型停止生成更多内容的特定文本序列。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1f9fc4514062b82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user_input = prompt\n",
    "response = openai.ChatCompletion.create(\n",
    "    # model='gpt-3.5-turbo',\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": user_input},\n",
    "    ],\n",
    "    # 2024:1:6 谢若天师兄提示\n",
    "    temperature=0.0,  # 调整随机性\n",
    "    max_tokens=50,  # 输出的最大长度\n",
    "    frequency_penalty=0.5,  # 减少重复\n",
    "    presence_penalty=0.0  # 鼓励创新\n",
    ")\n",
    "model_reply = response['choices'][0]['message']['content']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:22:01.831442Z",
     "start_time": "2024-01-06T03:21:59.847640Z"
    }
   },
   "id": "2efdb8e5fac721e0",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'4.30 GHz::8 cores::16 Threads::11.00 MB::85.3 GB/s'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reply"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:22:04.545907Z",
     "start_time": "2024-01-06T03:22:04.542448Z"
    }
   },
   "id": "7c4d2b34174f0fc9",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T03:21:17.502034Z",
     "start_time": "2024-01-06T03:21:17.498722Z"
    }
   },
   "id": "1f455950d3d2d6c9",
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
